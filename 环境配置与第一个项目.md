[TOC]



# 环境配置(针对pytorch项目)



## 环境变量

**环境变量**一般是指在操作系统中用来指定操作系统运行环境的一些参数，是操作系统为了满足不同的应用场景预先在系统内预先设置的一大批全局变量。

在Linux系统中，环境变量可以分为以下几类：

* 系统级环境变量：
  系统级环境变量对所有用户和进程都可见。它们通常在系统启动时被设置，并被所有用户和进程共享。一些常见的系统级环境变量包括PATH（用于指定可执行文件的搜索路径）、LANG（用于设置系统语言环境）等。

* 用户级环境变量：
  用户级环境变量是每个用户独立设置的，只对该用户及其相关进程可见。这些变量可以在登录时通过不同的配置文件（如.bashrc、.bash_profile、.profile等）设置。常见的用户级环境变量包括HOME（指定用户的主目录路径）、USER（当前用户名）等。

* 进程级环境变量：
  进程级环境变量是由特定进程设置的，并且仅对该进程及其子进程可见。这些变量可以通过编程语言（如C语言中的setenv函数）在程序中进行设置，或者通过终端命令行在特定的进程上下文中设置。

需要注意的是，系统级环境变量和用户级环境变量通常是通过配置文件进行设置和管理的。对于系统级环境变量，常见的配置文件包括/etc/profile和/etc/environment。对于用户级环境变量，常见的配置文件包括用户的个人配置文件（如.bashrc、.bash_profile、.profile等）。



**常见的Linux环境变量：**

* PATH：决定了系统在哪些目录中查找可执行文件。当你输入一个命令时，系统会在PATH中定义的目录中查找该命令的可执行文件。

* HOME：指定当前用户的主目录路径。

* USER：当前用户的用户名。

* SHELL：指定当前用户默认使用的shell。

* LANG：指定系统的默认语言。

* LD_LIBRARY_PATH：指定系统在哪些目录中查找共享库文件。

* TERM：指定当前终端的类型。

* PS1：定义命令行提示符的格式。

* PS2：定义多行命令的提示符的格式。
  

安装 Conda、Java、Python 等软件后要更新环境变量 `PATH`，系统通过 `PATH` 环境变量中的目录，来查找你输入的命令（如 `python`, `java`, `conda`）的可执行文件



临时配置环境变量,在终端执行：这个操作：只在**你当前的 shell 会话中有效**；如果你打开另一个终端窗口，CUDA 路径不会自动加进去；重启或关闭终端就失效了。

```
export PATH=/usr/local/cuda/bin:$PATH
```



### CUDA_VISIABLE_DEVICES

`CUDA_VISIBLE_DEVICES` 是一个 **环境变量**，用于 **控制 PyTorch 或其他基于 CUDA 的深度学习框架可以看到/使用哪些 GPU**。

#### 使用方式

- **临时设置（推荐）**
   直接写在命令前：

  ```
  CUDA_VISIBLE_DEVICES=0,1 python train.py
  ```

- **在 Python 中控制（不推荐）**
   用 `os.environ`：

  ```
  import os
  os.environ["CUDA_VISIBLE_DEVICES"] = "1"
  import torch  # 放在设置之后
  ```

- **长期设置（不推荐）**
   写进 `.bashrc`：

  ```
  export CUDA_VISIBLE_DEVICES=0
  ```





## .bashrc

 `bash` 是 Linux 和类 Unix 系统中最常用的 **命令行解释器（shell）**

<img src="C:\Users\SHI\AppData\Roaming\Typora\typora-user-images\image-20250709103931579.png" alt="image-20250709103931579" style="zoom: 80%;" />

**配置文件是用来定义或修改环境变量的文件**，它们会在你打开终端或登录系统时被自动执行，从而设置好你的环境变量。

`.bashrc`是 Linux 和类 Unix 系统中 **bash shell 的用户级配置文件**，一般位于 ~/.bashrc

在`.bashrc`中更新`PATH`方法：

* 打开./bashrc文件

```
vim ~/.bashrc
```

* 在文件尾添加新路径，保存并退出

```export PATH="新路径:$PATH"
export PATH="新路径:$PATH"
```

* 刷新./bashrc文件令其立刻生效

```
source ~/.bashrc
```

* 验证PATH是否有效(观察输出路径是否正确)

```
echo $PATH
```

`./bashrc`示例

```
# 设置 Conda 路径
export PATH="$HOME/anaconda3/bin:$PATH"

# 设置自定义 Python
export PATH="/opt/python3.11/bin:$PATH"

# 设置 Java 路径，可用变量JAVA_HOME
export JAVA_HOME="/usr/lib/jvm/java-11-openjdk"
export PATH="$JAVA_HOME/bin:$PATH"
```

目前的conda等会自动在bashrc文件中加入一段初始化脚本，这个脚本的作用是：

- 动态把 `conda` 命令加入当前 shell 环境
- 运行时修改 `PATH`，激活 conda base 环境
- 支持 `conda activate` 和 `conda deactivate`

**它是写在 `~/.bashrc` 文件里的**，但不会直接修改系统的全局 `PATH`，而是在你打开新终端或 `source ~/.bashrc` 时生效，且永久生效，不会因为关闭终端或重启而失效





## 代理http_proxy, https_proxy

代理服务器（Proxy Server）是一个中间服务器，它在客户端（你）和目标服务器（如 Google、GitHub）之间转发请求。它的作用包括：

- **突破防火墙 / 网络限制**（例如在学校、公司网络无法访问外网时）
- **隐藏真实 IP 地址**
- **加速访问国外网站（科学上网）**
- **流量过滤或安全监控**



http_proxy / https_proxy是环境变量，告诉系统或程序“访问网页或下载数据时请通过代理服务器。

- `http_proxy`：处理 HTTP 协议请求的代理
- `https_proxy`：处理 HTTPS 协议请求的代理

**格式如下**：

```
http_proxy=http://代理服务器IP:端口
https_proxy=http://代理服务器IP:端口
```



例如，如果你使用了本地代理（如 Clash、V2RayN），地址通常是：

```
http_proxy=http://127.0.0.1:7890
https_proxy=http://127.0.0.1:7890
```





# 深度学习项目准备

* 环境准备流程图

```
① 安装 Python 和 Conda（Miniconda/Miniforge）
         ↓
② 创建虚拟环境（指定 Python 版本）
         ↓
③ 安装框架（如 PyTorch、TensorFlow）
         ↓
④ 安装其他依赖包（如 numpy、scikit-learn、matplotlib 等）
         ↓
⑤ 验证 GPU、代码是否能正常运行
```





# TMUX

在训练 PyTorch 项目，尤其是运行时间比较长的训练任务（如几个小时甚至几天），掌握 tmux 的核心用法是非常必要的，可以避免断网、SSH掉线导致训练中断。

先安装tmux

## 常见 tmux session 操作

| 动作             | 命令                                                         |
| ---------------- | ------------------------------------------------------------ |
| 创建新 session   | `tmux new -s mysession`                                      |
| 查看所有 session | `tmux ls`                                                    |
| 进入 session     | `tmux attach -t mysession`                                   |
| 暂时离开         | `Ctrl + b`，然后按 `d`   / 或者  `tmux detach`/`tmux detach -s 会话名` |
| 杀掉 session     | `tmux kill-session -t mysession`                             |

### 完整训练流程

```
tmux new -s train_resnet18          # 启动会话
conda activate sjjenv               # 进入你的 PyTorch 环境
CUDA_VISIBLE_DEVICES=0 python train.py  # 指定GPU启动训练
Ctrl + b，d                         # 断开会话

#随后你可以关掉终端，训练照常运行。
#回来看结果：

tmux attach -t train_resnet18
```



### 配合日志保存（推荐）

在 `tmux` 中运行训练任务时，为了不丢失输出信息，可以这样写：

```
python train.py | tee train_log.txt
```

这样训练的 `stdout` 会保存到 `train_log.txt`，又能实时看到控制台输出，非常实用。



### 查看当前是否处于对话

* 方法一：环境变量检查

在 `tmux` 中，会自动设置环境变量 `TMUX`。你可以执行以下命令查看：

```
echo $TMUX
```

​	如果输出是一个路径（例如 `/tmp/tmux-1000/default,1234,0`），说明你 **正在 tmux 会话中**。

​	如果输出为空，说明你 **不在 tmux 会话中**。

* 方法二：使用 `tmux display-message`（推荐）

```
tmux display-message -p '#S'
```

​	如果你当前在 `tmux` 中，它会显示当前会话名称。



### tmux 多窗口使用

- `Ctrl + b` 然后 `c`：新建窗口（可用于运行 `htop`/`nvidia-smi`）
- `Ctrl + b` 然后 `n/p`：在多个窗口之间切换（next/previous）
- `Ctrl + b` 然后 `"`（双引号）：水平分屏
- `Ctrl + b` 然后 `%`：垂直分屏
- `Ctrl + b` 然后 `x`：关闭当前窗格

举例：
 你可以在一个窗口训练模型，在另一个窗口实时查看 GPU 占用：

```
watch -n 1 nvidia-smi
```



### 查看所有正在训练的脚本

```
ps aux | grep train.py
```





# Python

* 查看当前已安装python版本

```
python --version
```

* 运行python文件

```
python file.py
```

<img src="C:\Users\SHI\AppData\Roaming\Typora\typora-user-images\image-20250709113653116.png" alt="image-20250709113653116" style="zoom:80%;" />



# conda

conda是一个 **开源的包管理器 + 环境管理器**

* 包管理器，类似于 pip，但功能更强大。会自动安装依赖包，支持从多个镜像源（如 TUNA、清华、Anaconda Cloud）下载,例如：

```
conda install numpy
conda remove pandas
conda update scikit-learn
```

* 虚拟环境管理器，允许你为每个项目创建独立的 Python 环境，不同项目可使用不同的 Python 版本或依赖版本，例如：

```
conda create -n myenv python=3.12
conda activate myenv
python  # 进入 Python 交互环境，检查版本,临时试验、调试、学习（用的不多
exit    # 退出 Python
conda deactivate	#退出当前激活的环境，返回到 base 环境或系统默认环境
```

* 查看所有虚拟环境

```
conda env list
```

* 删除环境

```
conda remove -n myenv --all
```

* 更新conda本身(建议在base环境下进行)

```
conda activate base
conda update -n base -c conda-forge conda
```

* 验证环境是否正常

```
conda info --envs      # 查看所有环境
python --version       # 应该输出 Python 3.12.11
which python           # 应该指向 sjjenv 的 bin 目录
```

<img src="C:\Users\SHI\AppData\Roaming\Typora\typora-user-images\image-20250709113432537.png" alt="image-20250709113432537" style="zoom:80%;" />

* 导出当前环境为 `yml` 文件（方便复现）

```
conda env export > sjjenv.yml
```



# CUDA

Conda 环境隔离的是软件栈（Python + 包 + 依赖库），不隔离硬件驱动和操作系统资源，因此nvcc显示出结果一样，但每个conda环境需要单独安装python和pytorch

```
import torch
print(torch.__version__)
```

该命令显示的是表示 **PyTorch 是用哪个 CUDA 版本编译出来的**。

即安装pytorch时执行的

```
pip install torch==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118
```







nvidia-smi与nvcc两者不同



| `nvcc --version` | 显示系统 CUDA Toolkit 编译器版本 | 系统级 CUDA |
| ---------------- | -------------------------------- | ----------- |
|                  |                                  |             |

| `torch.version.cuda` | 显示当前 PyTorch 使用的 CUDA 版本 |
| -------------------- | --------------------------------- |
|                      |                                   |



CUDA的组成



指定用于训练得到的GPU

CUDA_VISIBLE_DEVICES=1 python train.py



下载对应CUDA的pytorch



### cuDNN





# Pytorch

查看pytorch安装信息

进入python后

```
import torch
print(torch.__version__)
print(torch.cuda.is_available())
print(torch.version.cuda)
```



# 第一个pytorch项目

## 目录结构

project_root/   ← 鉴别猫狗项目
├── dataset/
│   ├── train/
│   │   ├── cat/   ← 10 张猫的图片（命名如 cat1.jpg, cat2.jpg...）
│   │   └── dog/   ← 10 张狗的图片（dog1.jpg, dog2.jpg...）
│   ├── val/
│   │   ├── cat/   ← 验证集可以复制训练集几张过来（或随机划分）
│   │   └── dog/
├── train.py         ← 主训练脚本
├── model/           ← 模型保存目录
├── outputs/         ← 日志输出/可视化预测
├── requirements.txt ← 环境依赖



`requirements.txt` 是一个用来记录 Python 项目的依赖库及其版本的**纯文本文件**，在 Python 项目中非常常见，特别是和 `pip` 搭配使用。

假设你的项目用到了三方库，写成requirements.txt后为

```
torch==2.1.0
torchvision==0.16.0
numpy>=1.21.0
matplotlib
```

运行

```
pip install -r requirements.txt
```

含义是：**读取 `requirements.txt` 中的每一行，并依次安装对应库及其版本**。



如果你已经在虚拟环境中安装了所需的库，想保存下来：

```
pip freeze > requirements.txt
```



通过 `CUDA_VISIBLE_DEVICES` 指定 GPU运行项目，并输入到日志文件中（不会在命令行上显示了

CUDA_VISIBLE_DEVICES=1 python your_script.py > log.txt



## 环境准备

* 连接远程服务器以后
* conda进虚拟环境
* 安装对应python和CUDA版本的pytorch
* 从github上面clone代码
* tmux开始一个新会话
* CUDA_VISIBLE_DEVICES=7 python train.py > log.txt 训练代码
* push到远程



## 代码解析

[Shugify/test: 临时实验测试](https://github.com/Shugify/test)

```
import os # 导入 'os' 模块，用于与操作系统交互，比如创建目录或拼接文件路径。
import torch # 导入 PyTorch 的核心库，这是所有张量操作和神经网络构建的基础。
import torch.nn as nn # 导入 PyTorch 的 'nn' 模块，它包含了所有神经网络的构建块（例如，全连接层 Linear, 卷积层 Conv2d）。
import torch.optim as optim # 导入 'optim' 模块，它提供了各种优化算法（如 SGD, Adam）来更新模型的权重。
from torchvision import datasets, models, transforms # 从 torchvision 库中导入特定的模块：
# 'datasets' 用于常用的数据集（例如 ImageFolder，可以方便地加载按文件夹组织的图像数据）。
# 'models' 用于预训练的模型（例如 ResNet）。
# 'transforms' 用于图像的各种预处理和增强操作。
from torch.utils.data import DataLoader # 导入 DataLoader，它能高效地以批次（batch）形式加载数据。

# ---------- 路径配置 ---------- # 这是一个注释，表示以下是关于文件路径的配置。
data_dir = 'dataset' # 定义你的图像数据集所在的根目录（例如，里面会有 'train' 和 'val' 子文件夹）。
model_dir = 'model' # 定义训练好的模型将要保存的目录。
os.makedirs(model_dir, exist_ok=True) # 如果 'model' 目录不存在，则创建它。'exist_ok=True' 参数表示如果目录已经存在，则不会引发错误。

# ---------- 使用GPU ---------- # 注释，表示以下是关于设备（GPU/CPU）的设置。
device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # 检查是否可用 CUDA（NVIDIA GPU 的并行计算平台）。如果可用，则使用 'cuda' 设备；否则，退回到 'cpu'（中央处理器）。
print("Using device:", device) # 打印出当前将用于计算的设备是 GPU 还是 CPU。

# ---------- 数据预处理 ---------- # 注释，表示以下是数据预处理的设置。
data_transforms = { # 定义一个字典，包含训练集和验证集不同的数据转换（预处理）规则。
    'train': transforms.Compose([ # 对训练数据应用一系列转换操作：
        transforms.Resize((224, 224)), # 将图像大小统一调整为 224x224 像素。这是许多预训练模型（如 ResNet）的标准输入尺寸。
        transforms.RandomHorizontalFlip(), # 以 0.5 的概率随机对图像进行水平翻转。这是一种数据增强技术，可以增加数据的多样性，帮助模型更好地泛化。
        transforms.ToTensor(), # 将 PIL Image 或 NumPy ndarray 格式的图像转换为 PyTorch 张量 (Tensor)。它还会将像素值从 [0, 255] 归一化到 [0.0, 1.0]。
        transforms.Normalize([0.5]*3, [0.5]*3) # 对图像张量进行标准化。它会将每个颜色通道的像素值调整为均值为 0.5，标准差为 0.5。这意味着像素值将被缩放到 [-1, 1] 之间。这有助于模型的训练收敛。
    ]),
    'val': transforms.Compose([ # 对验证数据应用一系列转换操作（通常比训练集少，因为验证集不需要数据增强）：
        transforms.Resize((224, 224)), # 将图像大小统一调整为 224x224 像素。
        transforms.ToTensor(), # 将图像转换为 PyTorch 张量。
        transforms.Normalize([0.5]*3, [0.5]*3) # 对图像张量进行标准化。
    ]),
}

# ---------- 加载数据 ---------- # 注释，表示以下是数据加载的设置。
batch_size = 4 # 定义每个训练或验证批次中包含的图像数量。较大的批次大小通常能更稳定地估计梯度，但可能需要更多内存。
image_datasets = { # 创建一个字典，用于存储训练集和验证集的图像数据集。
    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) # 对于 'train' 和 'val' 键：
    # `os.path.join(data_dir, x)` 会拼接出完整的数据集路径，例如 'dataset/train' 和 'dataset/val'。
    # `datasets.ImageFolder` 会自动识别这些路径下的子文件夹作为类别，并加载其中的图像。
    # `data_transforms[x]` 会应用对应的数据转换规则。
    for x in ['train', 'val'] # 这是一个字典推导式，循环遍历 'train' 和 'val'。
}
dataloaders = { # 创建一个字典，用于存储训练集和验证集的 DataLoader。
    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) # 对于 'train' 和 'val' 键：
    # `DataLoader` 接收一个数据集 (`image_datasets[x]`)，并根据 `batch_size` 和 `shuffle` 参数创建可迭代的数据加载器。
    # `shuffle=True` (通常用于训练集) 表示在每个 epoch 开始时打乱数据，以确保模型不会学习到数据的固定顺序。
    for x in ['train', 'val']
}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} # 创建一个字典，记录训练集和验证集中图像的总数量。
class_names = image_datasets['train'].classes # 从训练数据集中获取所有类别的名称。`ImageFolder` 会根据子文件夹名称自动识别。
print("Classes:", class_names) # 打印出识别到的类别名称。

# ---------- 构建模型 ---------- # 注释，表示以下是模型构建的部分。
model = models.resnet18(pretrained=True) # 加载一个预训练的 ResNet18 模型。`pretrained=True` 表示下载并在 ImageNet 数据集上预训练好的权重。使用预训练模型可以显著加速训练，尤其是在数据量不足时。
model.fc = nn.Linear(model.fc.in_features, 2) # 修改 ResNet18 的最后一层（全连接层，通常命名为 `fc`）。
# `model.fc.in_features` 获取原始全连接层的输入特征数量。
# `nn.Linear(input_features, output_features)` 创建一个新的全连接层。
# 这里 `2` 表示输出类别数量，因为这是一个二分类任务（例如，猫和狗）。这样，模型就能适应你的特定任务。
model = model.to(device) # 将模型移动到之前确定的设备上（GPU 或 CPU）。如果使用 GPU，这将允许模型在 GPU 上进行计算。

# ---------- 损失和优化器 ---------- # 注释，表示以下是损失函数和优化器的设置。
criterion = nn.CrossEntropyLoss() # 定义损失函数。`nn.CrossEntropyLoss` 适用于多分类任务（包括二分类），它结合了 LogSoftmax 和 NLLLoss，常用于分类问题。
optimizer = optim.Adam(model.parameters(), lr=1e-4) # 定义优化器。`optim.Adam` 是一种常用的优化算法，通常在实践中表现良好。
# `model.parameters()` 告诉优化器要更新哪些参数（即模型的所有可学习权重和偏置）。
# `lr=1e-4` 设置学习率（learning rate），控制每次参数更新的步长大小。

# ---------- 训练函数 ---------- # 注释，表示以下是模型的训练函数定义。
def train_model(model, criterion, optimizer, num_epochs=10): # 定义一个名为 `train_model` 的函数，接受模型、损失函数、优化器和训练轮数作为参数。
    for epoch in range(num_epochs): # 开始训练循环，每个 `epoch` 遍历整个数据集一次。
        print(f"\nEpoch {epoch+1}/{num_epochs}") # 打印当前是第几个 epoch。
        print("-" * 30) # 打印一条分隔线，美化输出。

        for phase in ['train', 'val']: # 在每个 epoch 中，我们分别进行训练阶段和验证阶段。
            if phase == 'train': # 如果当前是训练阶段：
                model.train() # 将模型设置为训练模式。这会启用像 Dropout 和 BatchNorm 这样的层，它们在训练和评估时行为不同。
            else: # 如果当前是验证阶段：
                model.eval() # 将模型设置为评估模式。这会关闭 Dropout，并使用 BatchNorm 层的统计均值和方差，而不是批次统计。

            running_loss, running_corrects = 0.0, 0 # 初始化当前阶段的累计损失和正确预测数。

            for inputs, labels in dataloaders[phase]: # 遍历当前阶段的 DataLoader，逐批次获取输入图像和对应的真实标签。
                inputs, labels = inputs.to(device), labels.to(device) # 将输入图像和标签数据移动到指定的设备（GPU 或 CPU）上，以便进行计算。

                optimizer.zero_grad() # **重要步骤：** 在每次反向传播之前，清零所有参数的梯度。
                # PyTorch 默认会累积梯度，如果不清零，上一次的梯度会和当前的梯度叠加，导致错误的结果。

                with torch.set_grad_enabled(phase == 'train'): # 这是一个上下文管理器。
                    # 如果 `phase == 'train'` (训练阶段)，`torch.set_grad_enabled(True)` 会启用梯度计算（默认行为）。
                    # 如果 `phase == 'val'` (验证阶段)，`torch.set_grad_enabled(False)` 会禁用梯度计算。
                    # 在验证阶段禁用梯度计算可以节省内存并加速推理，因为此时我们不需要计算梯度来更新权重。
                    outputs = model(inputs) # **前向传播：** 将输入数据 `inputs` 传入模型，得到模型的输出 `outputs`（即 logit）。
                    _, preds = torch.max(outputs, 1) # 从模型的输出中获取预测结果。`torch.max(outputs, 1)` 返回每行（每个样本）的最大值和其对应的索引。`_` 表示我们不关心最大值本身，只关心索引（即预测的类别）。
                    loss = criterion(outputs, labels) # **计算损失：** 使用定义的损失函数 `criterion`，比较模型的 `outputs` 和真实的 `labels`，计算当前批次的损失。

                    if phase == 'train': # 如果当前是训练阶段：
                        loss.backward() # **反向传播：** 计算损失相对于模型所有可学习参数的梯度。
                        optimizer.step() # **更新权重：** 根据计算出的梯度和优化器规则，更新模型的权重。

                running_loss += loss.item() * inputs.size(0) # 累加当前批次的损失到 `running_loss`。`loss.item()` 获取单个损失值（Python 数值），`inputs.size(0)` 是当前批次的图像数量。
                running_corrects += (preds == labels).sum().item() # 累加当前批次中正确预测的数量。`(preds == labels)` 会生成一个布尔张量，`.sum()` 计算其中 True 的数量，`.item()` 转换为 Python 数值。

            epoch_loss = running_loss / dataset_sizes[phase] # 计算当前 epoch 的平均损失（总损失除以数据总数）。
            epoch_acc = running_corrects / dataset_sizes[phase] # 计算当前 epoch 的准确率（正确预测数除以数据总数）。
            print(f"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}") # 打印当前阶段的损失和准确率，保留四位小数。

    return model # 训练完成后，返回训练好的模型。

# ---------- 启动训练 ---------- # 注释，表示以下是启动训练过程。
model = train_model(model, criterion, optimizer, num_epochs=10) # 调用 `train_model` 函数，开始模型的训练过程，这里设置为训练 10 个 epoch。训练好的模型会覆盖原来的 `model` 变量。

# ---------- 保存模型 ---------- # 注释，表示以下是保存模型的步骤。
model_path = os.path.join(model_dir, "resnet18_catdog.pth") # 构建模型保存的完整路径和文件名。
torch.save(model.state_dict(), model_path) # 保存模型的**状态字典**。`model.state_dict()` 包含了模型所有学习到的参数（权重和偏置）。
# 通常建议只保存状态字典，而不是整个模型对象，因为它更灵活，且更不容易受代码结构变化的影响。
print("Model saved to:", model_path) # 打印模型保存的路径。

```



### 1. **导入所需的库**

```
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
```

- `os`: 用于文件和路径操作，比如创建文件夹。
- `torch`: PyTorch的核心库，包含了张量（tensor）、模型、损失函数等。
- `torch.nn`: 包含神经网络的层、损失函数等工具。
- `torch.optim`: 包含优化器，比如Adam、SGD等。
- `datasets`, `models`, `transforms` 来自 `torchvision`，专门处理计算机视觉任务的工具库。`datasets` 用来加载标准数据集，`models` 提供了预训练的深度学习模型，`transforms` 用于数据预处理（如图像裁剪、翻转等）。
- `DataLoader`: 用于将数据集分批次加载到模型中。



### 2. **路径配置**

```
data_dir = 'dataset'
model_dir = 'model'
os.makedirs(model_dir, exist_ok=True)
```

- `data_dir`: 用于存放数据集的目录，`dataset` 是数据集的根目录。
- `model_dir`: 用于存放训练后模型的目录，`model` 用来保存训练好的模型。
- `os.makedirs(model_dir, exist_ok=True)`: 创建 `model` 目录，`exist_ok=True`表如果该目录已经存在则不会报错。



### 3. **选择设备 (GPU 或 CPU)**

```
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)
```

- 判断是否有可用的GPU，如果有，就使用GPU，否则使用CPU进行训练。
- `torch.cuda.is_available()` 用来检查是否可以使用GPU。
- `torch.device` 可以让我们指定计算设备，`cuda` 表示GPU，`cpu` 表示CPU。



### 4. **数据预处理**

```
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.5]*3, [0.5]*3)
    ]),
    'val': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5]*3, [0.5]*3)
    ]),
}
```

- `transforms.Compose`: 用来组合多个数据预处理操作。
- `transforms.Resize((224, 224))`: 将输入图像调整为 `224x224` 的大小。ResNet18 的标准输入大小是 `224x224`。
- `transforms.RandomHorizontalFlip()`: 以 0.5 的概率随机对图像进行水平翻转。这是一种数据增强技术，可以增加数据的多样性，帮助模型更好地泛化。
- `transforms.ToTensor()`:  将 PIL Image 或 NumPy ndarray 格式的图像转换为 PyTorch 张量 (Tensor)。它还会将像素值从 [0, 255] 归一化到 [0.0, 1.0]。
- `transforms.Normalize([0.5]*3, [0.5]*3)`: 对图像张量进行标准化。它会将每个颜色通道的像素值调整为均值为 0.5，标准差为 0.5。这意味着像素值将被缩放到 [-1, 1] 之间。这有助于模型的训练收敛。    ]),（对RGB三个通道都使用相同的均值和标准差）。



### 5. **加载数据集**

```
batch_size = 4
image_datasets = {
    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])
    for x in ['train', 'val']
}
dataloaders = {
    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)
    for x in ['train', 'val']
}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes
print("Classes:", class_names)
```

- `image_datasets`:  创建一个字典，用于存储训练集和验证集的图像数据集

- `datasets.ImageFolder`: 适用于图像文件夹结构的数据集加载器，对于 'train' 和 'val' 键，要求数据集的文件夹结构是：

  ```
  dataset/
      train/
          class1/
          class2/
      val/
          class1/
          class2/
  ```

- `os.path.join(data_dir, x)` 会拼接出完整的数据集路径，例如 'dataset/train' 和 'dataset/val'。     `datasets.ImageFolder` 会自动识别这些路径下的子文件夹作为类别（键），并加载其中的图像。    `data_transforms[x]` 会应用对应的数据转换规则。

- `DataLoader`: 接收一个数据集 (`image_datasets[x]`)，并根据 `batch_size` 和 `shuffle` 参数创建可迭代的数据加载器。

  - `batch_size=4`: 每次加载4张图片。定义每个训练或验证批次中包含的图像数量。较大的批次大小通常能更稳定地估计梯度，但可能需要更多内存。
  - `shuffle=True`: 每个epoch开始时，数据会被随机打乱，以确保模型不会学习到数据的固定顺序。

- `dataset_sizes`: 记录训练和验证集的样本数。

- `class_names`: 获取类别名称（即文件夹名称）。



### 6. **构建模型**

```
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 2)  # 2类
model = model.to(device)
```

- `models.resnet18(pretrained=True)`: 加载一个预训练的 ResNet18 模型。

- `pretrained=True` 表示下载并在 ImageNet 数据集上预训练好的权重。使用预训练模型可以显著加速训练，尤其是在数据量不足时。

- `model.fc = nn.Linear(model.fc.in_features, 2)`: 将模型的最后一层全连接层替换为一个新的全连接层，这个层的输出是2个类别（猫或狗）。

  - `model.fc.in_features` 是原模型最后一层的输入特征数。
  - `nn.Linear(input_features, output_features)` 创建一个新的全连接层。

- `model.to(device)`: 将模型移动到 GPU 或 CPU。

  

### 7. **损失函数与优化器**

```
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)
```

- `nn.CrossEntropyLoss()`: 交叉熵损失函数，用于多分类任务。
- `optim.Adam(model.parameters(), lr=1e-4)`: Adam优化器，用于训练模型，学习率设置为 `1e-4`。
  - `model.parameters()` 告诉优化器要更新哪些参数（即模型的所有可学习权重和偏置）。
  - `lr=1e-4` 设置学习率（learning rate），控制每次参数更新的步长大小。



### 8. **训练函数**

```
def train_model(model, criterion, optimizer, num_epochs=10):
    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")
        print("-" * 30)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss, running_corrects = 0.0, 0

            for inputs, labels in dataloaders[phase]:
                inputs, labels = inputs.to(device), labels.to(device)

                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += (preds == labels).sum().item()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects / dataset_sizes[phase]
            print(f"{phase.capitalize()} Loss: {epoch_loss:.4f}  Acc: {epoch_acc:.4f}")

    return model
```

- `train_model`: 训练和验证模型。

  - `for epoch in range(num_epochs)`: 迭代指定次数（10次）。

  - `model.train()` 和 `model.eval()` 用于设置模型的训练模式或评估模式。

  - 关于`model.train()`和`model.eval()`区别

    |                  | Dropout行为                                                | BatchNorm 行为                                               |
    | ---------------- | ---------------------------------------------------------- | ------------------------------------------------------------ |
    | `moodel.tarin()` | Dropout 会随机丢弃一部分神经元，防止过拟合                 | 使用当前 batch 的均值和方差来进行归一化，并更新内部的 running mean 和 running var |
    | `model.eval()`   | Dropout 关闭，所有神经元都会参与计算，模型行为变为“确定性” | 使用训练时积累的 running mean 和 running var，不再更新       |

    

  - `optimizer.zero_grad()`: 在每次反向传播之前，清除上一轮的梯度。PyTorch 默认会累积梯度，如果不清零，上一次的梯度会和当前的梯度叠加，导致错误的结果。

  - `torch.set_grad_enabled(phase == 'train')`: 仅在训练阶段启用梯度计算。在验证阶段禁用梯度计算可以节省内存并加速推理，因为此时我们不需要计算梯度来更新权重。

  - `loss.backward()`: 计算梯度。

  - `optimizer.step()`: 更新模型参数。

  - 每个epoch计算训练和验证集的损失和准确率。

  

### 9. **启动训练与保存模型**

```
model = train_model(model, criterion, optimizer, num_epochs=10)

model_path = os.path.join(model_dir, "resnet18_catdog.pth")
torch.save(model.state_dict(), model_path)
print("Model saved to:", model_path)
```

- `train_model` 开始训练并返回训练好的模型。
- `torch.save(model.state_dict(), model_path)`: 将训练好的模型保存到 `model_dir` 目录下。
  - `.state_dict()` 保存的是模型的参数（权重和偏置）。



### 流程简单总结

先是数据加载，dataset配置好数据集路径，并且对图像进行一些调整，比如大小统一，随机反转增加多样性，并把它们转换为张量模式，然后dataloader通过getitem调取单个样本，collate_fn封装成batch。
配置数据集路径 和 定义转换规则 是在 __init__ 中完成的。
实际执行转换 (大小统一、随机翻转、转为张量) 是在 __getitem__ 中，对每一个被请求的样本独立完成的。
__init__ 负责全局设置，__getitem__ 负责单个样本的懒加载和处理


然后训练的时候是定义好使用的损失函数，优化器和神经网络，不是预训练的网络的化就要写一下init和forward

训练的时候，对于每个epoch，在训练集将模型调整为model.train，打开dropout和batchnorm，对应测试集是model.eval,把dropout关闭，batchnorm使用训练出的均值和方差。
接着逐个批次从数据集中取出数据输入神经网络，
对于训练集，每轮训练前需要使用zero_grad清空梯度为反向传播做准备，训练时启用梯度计算，前向传播得到logit，然后和gt_label计算损失，根据损失进行反向传播并更新权重参数
对于测试集的话，就只需要前向传播，不需要梯度计算反向传播等等，可以节约计算资源
最后就是计算一下这个epoch的平均损失和准确率



### 使用到的pytorch方法汇总

#### 1. 数据处理与加载

- **`torchvision.transforms.Compose([...])`**:
  - **作用**: 将多个图像转换操作（如调整大小、翻转、转换为张量、标准化）按顺序组合起来，形成一个转换流水线。
  - **例子**: `transforms.Compose([transforms.Resize(...), transforms.ToTensor()])`
- **`torchvision.transforms.Resize((height, width))`**:
  - **作用**: 将输入图像的大小统一调整为指定的 `(height, width)`。
  - **例子**: `transforms.Resize((224, 224))`
- **`torchvision.transforms.RandomHorizontalFlip()`**:
  - **作用**: 以 0.5 的概率随机对图像进行水平翻转。这是一种常见的数据增强技术，有助于提高模型的泛化能力。
- **`torchvision.transforms.ToTensor()`**:
  - **作用**: 将 PIL 图像或 NumPy `ndarray` 转换为 PyTorch 张量 (`Tensor`)。它还会自动将像素值从 `[0, 255]` 缩放到 `[0.0, 1.0]`。
- **`torchvision.transforms.Normalize([mean_r, mean_g, mean_b], [std_r, std_g, std_b])`**:
  - **作用**: 对张量图像的每个通道进行标准化操作，即 `(pixel - mean) / std`。这通常将像素值调整到特定范围（如 `[-1, 1]` 或 `[0, 1]` 附近），有助于模型训练的稳定性和收敛速度。
  - **例子**: `transforms.Normalize([0.5]*3, [0.5]*3)`
- **`torchvision.datasets.ImageFolder(root, transform)`**:
  - **作用**: 一个非常方便的数据集加载器，用于加载按文件夹结构组织的图像数据集。它会自动将子文件夹名作为类别标签。
  - **例子**: `datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'])`
- **`torch.utils.data.DataLoader(dataset, batch_size, shuffle)`**:
  - **作用**: 用于将 `Dataset` 对象包装成一个可迭代的数据加载器。它负责按批次（Batch）加载数据、打乱数据（`shuffle=True`）以及多线程数据加载，大大提高了数据加载效率。
  - **例子**: `DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)`



#### 2. 模型构建与配置

- **`torch.device("cuda" if torch.cuda.is_available() else "cpu")`**:
  - **作用**: 自动检测当前系统是否支持 CUDA（NVIDIA GPU），并创建一个 `torch.device` 对象，以便后续将数据和模型放在 GPU 或 CPU 上进行计算。
- **`torchvision.models.resnet18(pretrained=True)`**:
  - **作用**: 从 `torchvision.models` 中加载一个预训练的 ResNet-18 模型。`pretrained=True` 表示加载已经在大型 ImageNet 数据集上训练好的权重，这对于迁移学习非常有用。
- **`torch.nn.Linear(in_features, out_features)`**:
  - **作用**: 定义一个全连接层（也称为线性层或密集层）。它对输入数据进行线性变换 `y = xA^T + b`。
  - **例子**: `model.fc = nn.Linear(model.fc.in_features, 2)` 用于修改 ResNet 的输出层以适应你的任务。
- **`model.to(device)`**:
  - **作用**: 将整个神经网络模型（包括其所有参数和缓冲区）移动到指定的设备（GPU 或 CPU）上。这确保了模型在正确的硬件上执行计算。
- **`torch.nn.CrossEntropyLoss()`**:
  - **作用**: 定义一个交叉熵损失函数。它常用于多分类问题（也包括二分类），其内部集成了 `LogSoftmax` 和负对数似然损失（NLLLoss），因此模型的最后一层通常不需要单独的 Softmax 激活函数。
- **`torch.optim.Adam(model.parameters(), lr)`**:
  - **作用**: 定义 Adam 优化器。`Adam` 是一种常用的自适应学习率优化算法，通常在各种任务中表现良好。
  - `model.parameters()`: 告诉优化器要更新模型中所有可学习的参数（权重和偏置）。
  - `lr`: 设置学习率（Learning Rate），控制每次参数更新的步长大小。



#### 3. 训练与评估流程

- **`model.train()`**:
  - **作用**: 将模型设置为训练模式。这会影响到一些特定层的行为，例如 `Dropout` 层会随机丢弃神经元，`BatchNorm` 层会使用当前批次的统计信息进行归一化。
- **`model.eval()`**:
  - **作用**: 将模型设置为评估（或推理）模式。此时 `Dropout` 层会关闭，`BatchNorm` 层会使用在训练过程中学习到的全局平均值和方差进行归一化。这确保了模型在评估时的输出是确定性的。
- **`optimizer.zero_grad()`**:
  - **作用**: 将模型所有参数的梯度清零。**这是在每次反向传播之前必不可少的一步**。因为 PyTorch 默认会累积梯度，如果不清零，本次计算的梯度会与上次的叠加。
- **`with torch.set_grad_enabled(bool_flag)`**:
  - **作用**: 一个上下文管理器，用于临时控制是否启用梯度计算。
  - 当 `bool_flag` 为 `True` 时（例如在训练阶段），梯度计算被启用。
  - 当 `bool_flag` 为 `False` 时（例如在验证阶段），梯度计算被禁用，从而节省内存并加速推理。
- **`model(inputs)`**:
  - **作用**: 执行模型的前向传播。`inputs` 数据通过模型的各个层，最终输出原始的预测分数（Logits）。
- **`torch.max(input, dim)`**:
  - **作用**: 在指定的维度 `dim` 上找到张量 `input` 的最大值和对应的索引。
  - **例子**: `torch.max(outputs, 1)` 用于在模型输出的 Logits 中，找到每个样本得分最高的类别及其对应的类别 ID。
- **`loss.backward()`**:
  - **作用**: 执行反向传播。它根据损失值 `loss`，自动计算模型所有可学习参数的梯度。
- **`optimizer.step()`**:
  - **作用**: 根据之前计算的梯度和优化器设定的规则（如学习率），更新模型的参数（权重和偏置）。这是模型学习和改进的关键步骤。
- **`loss.item()`**:
  - **作用**: 从一个包含单个值的 PyTorch 张量中提取其 Python 数值。常用于获取当前批次的损失值。
- **`tensor.sum().item()`**:
  - **作用**: 将一个布尔张量（例如 `preds == labels` 比较结果）中 `True` 的数量求和，并转换为 Python 数值。用于计算正确预测的数量。
- **`torch.save(obj, f)`**:
  - **作用**: 将一个 PyTorch 对象（通常是模型的 `state_dict()`）保存到磁盘文件。
  - **例子**: `torch.save(model.state_dict(), model_path)` 推荐保存模型的参数字典而不是整个模型对象，因为它更灵活。



### 面试问题

#### 第一部分：基础概念与整体理解

这部分问题用于考察面试者是否理解代码的宏观流程和 PyTorch 的基本构成。

1. **整体流程理解**:

   > "你能用自己的话简要概括一下这个脚本的完整流程吗？从数据准备到模型保存，它都做了些什么？"

   - **考察点**: 对项目流程的整体把握能力，能否清晰地分步描述问题。
   - **优秀回答**: 应提到数据加载与预处理、模型定义（迁移学习）、损失函数与优化器设置、迭代训练与验证、最后保存模型权重这几个关键阶段。

2. **核心模块功能**:

   > "这个脚本导入了 torch, torch.nn, torch.optim 和 torchvision。你能分别解释一下这几个核心模块的作用吗？"

   - **考察点**: 对 PyTorch 生态系统基本组成的了解。
   - **优秀回答**:
     - torch: 核心库，提供多维张量（Tensor）对象和数学运算。
     - torch.nn: 神经网络模块，包含所有网络层（如卷积层、全连接层）、损失函数和容器。
     - torch.optim: 优化器模块，包含各种优化算法（如 Adam, SGD）。
     - torchvision: 视觉工具库，提供常用数据集、预训练模型和图像预处理方法。

3. **张量（Tensor）的概念**:

   > "脚本的核心是处理和计算'张量'（Tensor）。请问什么是张量？在这段代码中，哪些数据最终会以张量的形式存在？"

   - **考察点**: 对 PyTorch 最基本数据结构 "张量" 的理解。
   - **优秀回答**: 张量是 PyTorch 中的基本数据结构，类似于 NumPy 的 ndarray，但增加了在 GPU 上进行计算的能力。代码中的输入图像 (inputs) 和标签 (labels) 都会被转换成张量来进行模型计算。



#### 第二部分：数据处理 (transforms, Dataset, DataLoader)

这部分问题深入到数据准备的细节，这是任何深度学习项目的第一步。

1. **数据增强的目的**:

   > "在 data_transforms 中，为什么训练集（train）的预处理包含了 RandomHorizontalFlip，而验证集（val）却没有？这样做有什么好处？"

   - **考察点**: 对数据增强（Data Augmentation）的理解及其作用。
   - **优秀回答**: RandomHorizontalFlip 是一种数据增强技术，只在训练集上使用。它可以增加训练数据的多样性，让模型看到更多变化的图像，从而提高模型的泛化能力，防止过拟合。验证集是用来模拟真实测试场景的，因此不应该包含任何随机的数据增强，以保证评估结果的稳定和客观。

2. **图像预处理步骤**:

   > "请解释一下 transforms.ToTensor() 和 transforms.Normalize([0.5]*3, [0.5]*3) 这两行代码的具体作用。为什么标准化（Normalize）对模型训练很重要？"

   - **考察点**: 对具体图像变换操作的理解。
   - **优秀回答**:
     - ToTensor(): 将 PIL 图像或 NumPy 数组转换为 PyTorch 张量，并把像素值从 的范围缩放到 [0.0, 1.0]。
     - Normalize(): 用给定的均值和标准差对张量进行标准化。这里是将 的数据转换到 [-1, 1] 的范围。标准化可以使数据分布更稳定，有助于加速模型收敛并提高性能。

3. **DataLoader 的作用**:

   > "代码中使用了 DataLoader。相比于直接在一个 for 循环里遍历 ImageFolder 数据集，使用 DataLoader 提供了哪些关键功能？batch_size 和 shuffle=True 参数分别起什么作用？"

   - **考察点**: 对 DataLoader 核心功能的理解。
   - **优秀回答**: DataLoader 提供了三个核心功能：
     1. **批处理 (Batching)**: 将数据打包成一个个批次（batch）进行训练，由 batch_size 参数控制。
     2. **数据打乱 (Shuffling)**: 在每个 epoch 开始时随机打乱数据顺序，避免模型学习到数据的特定顺序，由 shuffle=True 控制。
     3. **并行加载**: 可以使用多个子进程并行加载数据，避免数据加载成为训练的瓶颈。



#### 第三部分：模型构建与迁移学习

这部分问题考察对迁移学习这一重要技术的理解。

1. **预训练模型**:

   > "这行代码 model = models.resnet18(pretrained=True) 是什么意思？什么是'预训练模型'？使用预训练模型有什么优点？"

   - **考察点**: 对迁移学习核心概念的理解。
   - **优秀回答**: pretrained=True 表示加载一个已经在大型数据集（如 ImageNet）上训练好的 ResNet18 模型权重。这种模型就是预训练模型。优点是模型已经学习到了通用的图像特征（如边缘、纹理），我们只需要在自己的小数据集上进行微调（fine-tuning），就可以用更少的数据和更短的时间达到很好的效果。

2. **模型微调（Fine-tuning）**:

   > "接下来的这行 model.fc = nn.Linear(model.fc.in_features, 2) 是在做什么？为什么要替换掉原来的全连接层（fc）？这里的数字 2 代表什么？"

   - **考察点**: 对如何修改预训练模型以适应新任务的理解。
   - **优秀回答**: 这行代码是在进行模型微调。它用一个新的全连接层替换掉了 ResNet18 原本用于 ImageNet 1000分类的最后一层。model.fc.in_features 自动获取了上一层输出的特征数。替换的原因是我们的新任务只有2个类别，而不是1000个。数字 2 代表我们任务的类别数量（例如，猫和狗）。



#### 第四部分：训练循环的核心逻辑

这是整个脚本最核心的部分，问题也最具考验性。

1. **model.train() 与 model.eval()**:

   > "在训练循环中，为什么在训练阶段（phase == 'train'）前要调用 model.train()，而在验证阶段前要调用 model.eval()？它们之间有什么关键区别？"

   - **考察点**: 这是 PyTorch 中一个非常重要且常见的考点。
   - **优秀回答**: model.train() 将模型设置为训练模式，这会启用 Dropout 和 BatchNorm 等层的训练行为。model.eval() 将模型设置为评估模式，会关闭 Dropout，并让 BatchNorm 使用在整个训练集上学习到的统计值，而不是当前批次的统计值。如果不进行切换，验证结果会因为 Dropout 的随机性而不稳定，BatchNorm 的计算也不正确。

2. **梯度计算三部曲**:

   > "请解释一下 optimizer.zero_grad(), loss.backward(), 和 optimizer.step() 这三个步骤的顺序和各自的作用。如果忘记调用 optimizer.zero_grad() 会发生什么？"

   - **考察点**: 对 PyTorch 自动求导和参数更新机制的理解，这是核心中的核心。
   - **优秀回答**:
     - optimizer.zero_grad(): 清除上一轮计算得到的梯度。
     - loss.backward(): 根据当前的损失，计算所有可学习参数的梯度（反向传播）。
     - optimizer.step(): 根据计算出的梯度和优化器算法，更新模型的权重。
     - 顺序不能错。如果忘记调用 optimizer.zero_grad()，每一轮的梯度都会被**累加**到之前的梯度上，导致参数更新方向错误，模型无法正常收敛。

3. **禁用梯度计算**:

   > "代码中使用了 with torch.set_grad_enabled(phase == 'train'):。为什么在验证（val）阶段要禁用梯度计算？这样做有什么好处？"

   - **考察点**: 对计算优化的理解。
   - **优秀回答**: 在验证阶段，我们只进行前向传播来评估模型性能，不需要计算梯度来更新权重。禁用梯度计算（torch.set_grad_enabled(False) 或 with torch.no_grad():）有两个好处：1. **节省显存**，因为不需要存储中间值用于反向传播。2. **加快计算速度**。

4. **.item() 的作用**:

   > "在累加损失时，代码写的是 running_loss += loss.item() * inputs.size(0)。为什么这里用 loss.item() 而不是直接用 loss？"

   - **考察点**: 对张量和计算图的细致理解。
   - **优秀回答**: loss 是一个包含梯度信息的零维张量。如果直接累加 loss，会导致计算图一直被保留在内存中，造成不必要的显存占用。loss.item() 会将张量中的数值提取为一个标准的 Python 数字，这样就不会保留计算图，可以有效释放内存。



#### 第五部分：设备管理与模型保存

1. **设备（GPU/CPU）管理**:

   > "model = model.to(device) 的作用是什么？在训练循环中，你还看到了哪些变量被移动到了 device 上？为什么数据也需要移动？"

   - **考察点**: 对 GPU 训练基本操作的理解。
   - **优秀回答**: model.to(device) 是将模型的所有参数和缓冲区移动到指定的设备（GPU 或 CPU）上。在训练循环中，输入数据 inputs 和标签 labels 也必须被移动到同一个设备上。因为模型和数据必须在同一个设备上才能进行计算，否则会报错。

2. **模型保存**:

   > "代码最后使用了 torch.save(model.state_dict(), model_path) 来保存模型。什么是'状态字典'（state_dict）？为什么推荐保存 state_dict 而不是直接保存整个 model 对象？"

   - **考察点**: 对模型持久化最佳实践的了解。
   - **优秀回答**: state_dict 是一个 Python 字典，它将模型的每一层映射到其可学习的参数（权重和偏置）张量。推荐只保存 state_dict 是因为它更灵活、更轻量、更不容易出错。如果直接保存整个模型对象，当你的代码文件结构发生变化时，可能就无法加载了。而只加载状态字典，你只需要先创建一个模型实例，再将权重加载进去即可，代码的依赖性更低。



